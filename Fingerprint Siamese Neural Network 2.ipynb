{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7848ec-a568-4fb9-92c3-fb816e0b79e0",
   "metadata": {},
   "source": [
    "# Fingerprint Siamese Neural Network 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3df359-294f-4e0d-8626-7db13c717f76",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is a Siamese Neural Network that compares the similarity between two unenhanced fingerpints.\n",
    "\n",
    "This Siamese Neural Network was adapted from https://github.com/kevinzakka/one-shot-siamese/blob/master/model.py for comparing images of characters. This model will be trained on a dataset of synthetically generated fringerprints using the [Anguli](https://dsl.cds.iisc.ac.in/projects/Anguli/) software.\n",
    "\n",
    "This model was run on 3/07/2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc677a8-8c3b-4a8c-b672-e8010062587f",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00820048-ed36-496c-afe3-9d75a5b508ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Augmentor\n",
    "!pip install pillow\n",
    "!pip install seaborn\n",
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc50a1-faf2-451e-abfd-ca2e1e35697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms.functional as Fv\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import Augmentor\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy import unravel_index \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from random import Random\n",
    "from skimage.util import random_noise\n",
    "\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91deac-5ff2-4bc1-a292-ebc289d90fd1",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a70ca4-34fe-45fa-a8ee-3a5429f2fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_file = \"checkpoint/SSNN_results.pt\"\n",
    "model_ckpt_filename = \"checkpoint/SSNN/SSNN_checkpoint\"\n",
    "\n",
    "im_size = (300, 206)\n",
    "var_max = 0.5\n",
    "\n",
    "num_train = 10000\n",
    "num_valid = 4000\n",
    "num_workers = 2\n",
    "shuffle = True\n",
    "augment = True\n",
    "\n",
    "sim_label = 1.0\n",
    "diff_label = 0.0\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of feature maps in Siamese Neural Network\n",
    "ndf = 256\n",
    "\n",
    "# Learning rate for optimizers\n",
    "slr = 0.0002\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 2\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "S_losses = []\n",
    "iters = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc43cfa-4d1a-4fba-81d5-8f0e0db71479",
   "metadata": {},
   "source": [
    "## Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b9688-cca5-4fe9-8747-e154fdff205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCkpt(filepath, epoch, netS, optimizerS, S_losses, iters):\n",
    "    if os.path.isfile(filepath):\n",
    "        os.remove(filepath)\n",
    "    torch.save({\n",
    "        'epoch' : epoch,\n",
    "        'netS_state_dict' : netS.state_dict(),\n",
    "        'optimizerS_state_dict' : optimizerS.state_dict(),\n",
    "        'S_losses' : S_losses,\n",
    "        'iters' : iters,\n",
    "    }, filepath)\n",
    "\n",
    "\n",
    "def showSampleFingerprintPairs(test_loader):\n",
    "    # Get a Batch of Sample Images\n",
    "    batch = next(iter(test_loader))\n",
    "    labels = batch[2][:8]\n",
    "\n",
    "    # Display the Sample Images\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch[0].to(device)[:8], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch[1].to(device)[:8], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "    c = 0\n",
    "    if labels is not None:\n",
    "        for l in labels:\n",
    "            if l == 1:\n",
    "                print(\"     same     \", end=\"\")\n",
    "            else:\n",
    "                print(\"     diff     \", end=\"\")\n",
    "            if c % 4 == 0:\n",
    "                print(\" \", end=\"\")\n",
    "            c += 1\n",
    "            \n",
    "        \n",
    "def validate(epoch):\n",
    "    # switch to evaluate mode\n",
    "    netD.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (val_Im1, val_Im2, val_y) in enumerate(valid_loader):\n",
    "        with torch.no_grad():\n",
    "            variation = random.uniform(0,var_max)\n",
    "            val_Im1 = torch.tensor(random_noise(val_Im1, mode='gaussian', mean=0, var=variation, clip=True), dtype=torch.float32)\n",
    "            val_Im1, val_Im2, val_y = val_Im1.to(device), val_Im2.to(device), val_y.to(device)\n",
    "            batch_size = val_Im1.shape[0]\n",
    "\n",
    "            # compute log probabilities\n",
    "            pred = torch.round(netD(val_Im1, val_Im2))\n",
    "            correct += (pred == val_y).sum().item()\n",
    "            total += batch_size\n",
    "            if total > num_valid:\n",
    "                break\n",
    "\n",
    "        # compute acc and log\n",
    "        valid_acc = (100. * correct) / total\n",
    "        return valid_acc\n",
    "    \n",
    "                \n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and\n",
    "    current value.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "class MovingAvg(object):\n",
    "    \"\"\"\n",
    "    Computes the moving average of values\n",
    "    \"\"\"\n",
    "    def __init__(self, length=10):\n",
    "        self.length = length\n",
    "        self.movingAvg = np.array([], dtype='f')\n",
    "        \n",
    "    def average(self):\n",
    "        return np.average(self.movingAvg)\n",
    "        \n",
    "    def pop(self):\n",
    "        if len(self.movingAvg > 0):\n",
    "            self.movingAvg = np.delete(self.movingAvg, 0, axis = 0)\n",
    "    \n",
    "    def push(self, val):\n",
    "        self.movingAvg = np.append(self.movingAvg, [val])\n",
    "        if len(self.movingAvg) > self.length:\n",
    "            self.movingAvg = np.delete(self.movingAvg, 0, axis = 0)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084286b6-4841-41e7-907e-d8fb22d69979",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736820f-2224-4a7f-9a9b-af300dc6166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader(target_dir, template_dir,\n",
    "                           batch_size,\n",
    "                           num_train,\n",
    "                           num_valid,\n",
    "                           shuffle=False,\n",
    "                           num_workers=2,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train \n",
    "    iterator over the dataset.\n",
    "    If using CUDA, num_workers should be set to `1` and pin_memory to `True`.\n",
    "    Args\n",
    "    ----\n",
    "    - target_dir: path directory to the target dataset.\n",
    "    - template_dir: path directory to the template dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to load the augmented version of the train dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset. Set\n",
    "      to `1` if using GPU.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      `True` if using GPU.\n",
    "    \"\"\"\n",
    "    fingerprints = [str(finger) for finger in range(1,10000+1)]\n",
    "    random.shuffle(fingerprints)\n",
    "    training_prints = fingerprints[:10000]\n",
    "    \n",
    "    # Get the Training Dataloader\n",
    "    train_dataset = FingerprintLoader(target_dir, template_dir, num_train, training_prints, batch_size)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return (train_loader)\n",
    "\n",
    "\n",
    "\n",
    "def get_train_valid_test_loaders(target_dir, template_dir,\n",
    "                                 batch_size,\n",
    "                                 num_train,\n",
    "                                 num_valid,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=2,\n",
    "                                 pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid \n",
    "    iterators over the dataset.\n",
    "    If using CUDA, num_workers should be set to `1` and pin_memory to `True`.\n",
    "    Args\n",
    "    ----\n",
    "    - target_dir: path directory to the target dataset.\n",
    "    - template_dir: path directory to the template dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - augment: whether to load the augmented version of the train dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset. Set\n",
    "      to `1` if using GPU.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      `True` if using GPU.\n",
    "    \"\"\"\n",
    "    # Each unique Fingerprint is named as a number from 1 to 10,000 (10000 unique fingerprints)\n",
    "    fingerprints = [str(finger) for finger in range(1,10000+1)]\n",
    "    random.shuffle(fingerprints)\n",
    "    training_prints = fingerprints[:7000]\n",
    "    validation_prints = fingerprints[7000:9500]\n",
    "    test_prints = fingerprints[9500:]\n",
    "    \n",
    "    # Get the Training Dataloader\n",
    "    train_dataset = FingerprintLoader(target_dir, template_dir, num_train, training_prints, batch_size)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    # Get the Validation Dataloader \n",
    "    valid_dataset = FingerprintLoader(target_dir, template_dir, num_valid, validation_prints, batch_size)\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "    \n",
    "    # Get the Test Dataloader \n",
    "    test_dataset = FingerprintLoader(target_dir, template_dir, num_valid, test_prints, batch_size)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return (train_loader, valid_loader, test_loader)\n",
    "    \n",
    "\n",
    "class FingerprintLoader(Dataset):\n",
    "    \"\"\"\n",
    "    This class is used to help load the fingerpint dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_dataset, template_dataset, num_train, dataset, batch_size):\n",
    "        \"\"\"\n",
    "        Initializes an instance for the FingerprintLoader class.\n",
    "\n",
    "        :param self: instance of the FingerprintLoader class\n",
    "        :param template_dataset: The template fingerprint dataset\n",
    "        :param target_dataset: The second fingerprint dataset to match against \n",
    "                               the template dataset\n",
    "        :param num_train: The number of images to load\n",
    "        :param dataset: List of fingerprints to include in the set\n",
    "        \"\"\"\n",
    "        super(FingerprintLoader, self).__init__()\n",
    "        self.target_dataset = target_dataset\n",
    "        self.template_dataset = template_dataset\n",
    "        self.fingerprints_dataset = dataset\n",
    "        self.num_train = num_train\n",
    "        self.augment = augment\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Helper function to return the length of the dataset\n",
    "\n",
    "        :param self: instance of the FingerprintLoader class\n",
    "        :return: the length of the dataset as an int\n",
    "        \"\"\"\n",
    "        return self.num_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getter function for accessing images from the dataset. This function will choose a \n",
    "        fingerprint image from the dataset and its corresponding enhanced fingerprint image.\n",
    "        It will then preprocess the images before returning them.\n",
    "        :param self: instance of the FingerprintLoader class\n",
    "        :param index: index for data image in set to return\n",
    "        :return: Image from dataset as a tensor\n",
    "        \"\"\"\n",
    "        target_im_filepath, template_im_filepath, y = self.chooseFingerprintPair()\n",
    "        targ_im = self.preprocessImage(target_im_filepath)\n",
    "        temp_img = self.preprocessImage(template_im_filepath)\n",
    "        y = torch.from_numpy(np.array([y], dtype=np.float32))\n",
    "        return targ_im, temp_img, y\n",
    "    \n",
    "    \n",
    "    def chooseFingerprintPair(self):\n",
    "        \"\"\"\n",
    "        Returns the filepath of the target fingerprint image and the enhanced template fingerprint.\n",
    "        :param self: instance of the FingerprintLoader class\n",
    "        :return: The filepaths for the \n",
    "        \"\"\"\n",
    "        target_im_filepath = \"targetim.jpg\" \n",
    "        enhanced_target_im_filepath = \"targetim.jpg\"  \n",
    "        y = float(random.randint(0,1))\n",
    "        # Chose image\n",
    "        while not os.path.isfile(target_im_filepath) or not os.path.isfile(template_im_filepath):\n",
    "            target_im_filepath = self.target_dataset + random.choice(os.listdir(self.target_dataset))\n",
    "            target_im_filepath +=  \"/Impression_1/\"\n",
    "            target_im_name = random.choice(self.fingerprints_dataset)\n",
    "            target_im_filepath = target_im_filepath + target_im_name + '.jpg'\n",
    "            template_im_name = target_im_name\n",
    "            if y < 0.9:\n",
    "                while template_im_name == target_im_name:\n",
    "                    template_im_name = random.choice(self.fingerprints_dataset)           \n",
    "            template_im_filepath = self.template_dataset + random.choice(os.listdir(self.template_dataset)) \\\n",
    "                + \"/Impression_1/\" + template_im_name + '.jpg' \n",
    "        return target_im_filepath, template_im_filepath, y\n",
    "    \n",
    "    \n",
    "    def preprocessImage(self, im_filepath):\n",
    "        \"\"\"\n",
    "        Preprocesses the image. This function will open the image, convert \n",
    "        it to grayscale, pad the image in order to make is square, \n",
    "        normalize the image, and then finally convert it to a tensor.\n",
    "        :param im: Filepath of the image to preprocess\n",
    "        :return: The preprocessed image\n",
    "        \"\"\"\n",
    "        im = Image.open(im_filepath)\n",
    "        # Convert to Grayscale\n",
    "        trans = transforms.Compose([#p.torch_transform(),\n",
    "                                transforms.Resize(im_size),\n",
    "                                transforms.Grayscale(1),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, ), (0.5, )),\n",
    "                              ])\n",
    "        # Apply the transformations to the images and labels\n",
    "        preprocessedImage = trans(im)\n",
    "        return preprocessedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042eb84-0f39-458f-8cde-c3967a8e806f",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305d41a-c12c-4221-a0f5-09445d88a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4221dff-4855-40ba-ae27-b23aaeba70e0",
   "metadata": {},
   "source": [
    "## Siamese Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc31745-d9ec-4222-a82d-3d4cc457ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Siamese Network for One-Shot Learning [1].\n",
    "    Siamese networts learn image representations via a supervised metric-based\n",
    "    approach. Once tuned, their learned features can be leveraged for one-shot\n",
    "    learning without any retraining.\n",
    "    References\n",
    "    ----------\n",
    "    https://github.com/kevinzakka/one-shot-siamese/blob/master/model.py\n",
    "    - Koch et al., https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "\n",
    "        # Device\n",
    "        self.ngpu = ngpu\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 1, 1, bias=False)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, 1, 4, 1, 1, bias=False)\n",
    "        # Batch Norm Layers\n",
    "        self.bn1 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf * 16)\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(1225, 512)\n",
    "        self.fc2 = nn.Linear(805, 1)\n",
    "\n",
    "    def sub_forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass the input image through 1 subnetwork.\n",
    "        Args\n",
    "        ----\n",
    "        - x: Contains either the first or second image pair across the input batch.\n",
    "        Returns\n",
    "        -------\n",
    "        - out: The hidden vector representation of the input vector x.\n",
    "        \"\"\"\n",
    "        out = F.leaky_relu_(self.conv1(x), 0.2)\n",
    "        out = F.leaky_relu_(self.bn1(self.conv2(out)), 0.2)\n",
    "        out = F.leaky_relu_(self.bn2(self.conv3(out)), 0.2)\n",
    "        out = F.leaky_relu_(self.bn3(self.conv4(out)), 0.2)\n",
    "        out = self.conv5(out).view(out.shape[0], -1)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Forward pass the input image pairs through both subtwins. An image\n",
    "        pair is composed of a left tensor x1 and a right tensor x2.\n",
    "        Concretely, we compute the component-wise L1 distance of the hidden\n",
    "        representations generated by each subnetwork, and feed the difference\n",
    "        to a final fc-layer followed by a sigmoid activation function to\n",
    "        generate a similarity score in the range [0, 1] for both embeddings.\n",
    "        Args\n",
    "        ----\n",
    "        - x1: a Variable of size (B, C, H, W). The left image pairs along the\n",
    "          batch dimension.\n",
    "        - x2: a Variable of size (B, C, H, W). The right image pairs along the\n",
    "          batch dimension.\n",
    "        Returns\n",
    "        -------\n",
    "        - probas: a Variable of size (B, 1). A probability scalar indicating\n",
    "          whether the left and right input pairs, along the batch dimension,\n",
    "          correspond to the same class. We expect the network to spit out\n",
    "          values near 1 when they belong to the same class, and 0 otherwise.\n",
    "        \"\"\"\n",
    "        # encode image pairs\n",
    "        h1 = self.sub_forward(x1)\n",
    "        h2 = self.sub_forward(x2)\n",
    "\n",
    "        # compute l1 distance\n",
    "        diff = torch.abs(h1 - h2)\n",
    "        \n",
    "        # score the similarity between the 2 encodings\n",
    "        scores = torch.sigmoid(self.fc2(diff))\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f3ed8-8c4d-400b-9ec3-05b81d9a9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Siamese Neural Network\n",
    "netS = SiameseNet().to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netS = nn.DataParallel(netS, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netS.apply(weights_init)    \n",
    "\n",
    "# Print the model\n",
    "print(netS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbef4c-da85-4711-853b-4922e38249a6",
   "metadata": {},
   "source": [
    "## Training Round 1\n",
    "\n",
    "The model will first be trained to match the enhanced fingerprint pair versions just as before. This will allow the subnetwork to learn how to extract the features from good quality fingerprints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6964c53-7c4f-4274-894e-37cdde5e2ce0",
   "metadata": {},
   "source": [
    "### Set Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e418cb7-a38a-449b-8208-3cc9295d3f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "torch.manual_seed(1)\n",
    "batch_size = 256\n",
    "\n",
    "kwargs = {}\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed(1)\n",
    "    kwargs = {'num_workers': ngpu, 'pin_memory': True}\n",
    "    \n",
    "target_dir =   \"/storage/Prepped_Fingerprints_206x300/Enhanced_Good/\"\n",
    "template_dir = \"/storage/Prepped_Fingerprints_206x300/Enhanced_Good/\"\n",
    "\n",
    "# Create the dataloader\n",
    "#num_train = 100000\n",
    "#num_valid = 4000\n",
    "num_train = 1000\n",
    "num_valid = 400\n",
    "data_loader = get_train_valid_test_loaders(target_dir, template_dir, batch_size, num_train, num_valid, shuffle, **kwargs)\n",
    "\n",
    "train_loader = data_loader[0]\n",
    "valid_loader = data_loader[1]\n",
    "test_loader = data_loader[2]\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "slr = 0.0002\n",
    "\n",
    "# Setup Adam optimizers for S\n",
    "optimizerS = optim.Adam(netS.parameters(), lr=slr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d091071-89d0-4c42-ac5d-2f45ec12b8ed",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "It was difficult to get access to large enough fingerprint datasets for training. This is because fingerprints are considered personal information, so this data is not commonly avaiable to everyone. Because of this, I ended up having to synthetically generate my own dataset using the [Anguli](https://dsl.cds.iisc.ac.in/projects/Anguli/) software. This generated dataset contains close to one million fingerprint images of varying qualities, which includes around 10,000 unique fingerprints. \n",
    "\n",
    "Below are some sample images that the Fingerprint Siamese Neural Network will be trained on, which is a subset of the dataset containing around 100,000 enhanced images of the good quality synthetic fingerprints in the datase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266d4e4-8572-42bb-9712-aec2ec371763",
   "metadata": {},
   "outputs": [],
   "source": [
    "showSampleFingerprintPairs(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aaf563-423f-44c1-aeb6-24af9bf3ac1d",
   "metadata": {},
   "source": [
    "### Siamese Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d6e53-9c24-4ae4-a7ce-4874de9344d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=[], num_epochs=10, start_epoch=1, iters=1):\n",
    "    # Lists to keep track of progress\n",
    "    iters = 0\n",
    "\n",
    "    print(\"\\n[*] Train on {} sample pairs, validate on {} sample pairs\".format(\n",
    "        num_train, num_valid)\n",
    "    )\n",
    "\n",
    "    gLossMvAvg = MovingAvg()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs+1):\n",
    "        print('\\nEpoch: {}/{}'.format(epoch, num_epochs)) \n",
    "        # switch to train mode\n",
    "        netS.train()\n",
    "        train_batch_time = AverageMeter()\n",
    "        train_losses = AverageMeter()\n",
    "        tic = time.time()\n",
    "        training_accuracy = 0.0\n",
    "        num_correct = 0\n",
    "        total = 0\n",
    "        with tqdm(total=num_train) as pbar:\n",
    "            for i, (x1, x2, y) in enumerate(train_loader): \n",
    "                x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "                output = netS(x1, x2).view(-1)\n",
    "                y = y.view(-1)\n",
    "                errS = criterion(output, y)\n",
    "                # Calculate the gradients for this batch\n",
    "                errS.backward()\n",
    "                # Update S\n",
    "                optimizerS.step()\n",
    "\n",
    "                for i in range(len(output)):\n",
    "                    label = 0.0\n",
    "                    if output[i] > 0.5:\n",
    "                        label = 1.0\n",
    "                    if label == y[i]:\n",
    "                        num_correct += 1\n",
    "                    total += 1\n",
    "\n",
    "                training_accuracy = num_correct / total * 100\n",
    "\n",
    "                # store batch statistics\n",
    "                toc = time.time()\n",
    "                train_batch_time.update(toc-tic)\n",
    "                tic = time.time()\n",
    "                pbar.set_description(\n",
    "                    (\n",
    "                        \"loss_S: {:.3f}   training accuracy: {:.6f}\".format(errS.item(), training_accuracy)\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "                # Save Losses for plotting later\n",
    "                S_losses.append(errS.item())\n",
    "                iters +=1\n",
    "\n",
    "        # Validate\n",
    "        netS.eval()\n",
    "        validation_accuracy = 0.0\n",
    "        num_valid_correct = 0\n",
    "        total_valid = 0\n",
    "        for i, (x1, x2, y) in enumerate(valid_loader): \n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            output = netS(x1, x2).view(-1)\n",
    "            y = y.view(-1)\n",
    "\n",
    "            for i in range(len(output)):\n",
    "                label = 0.0\n",
    "                if output[i] > 0.5:\n",
    "                    label = 1.0\n",
    "                if label == y[i]:\n",
    "                    num_valid_correct += 1\n",
    "                total_valid += 1\n",
    "\n",
    "        validation_accuracy = num_valid_correct / total_valid * 100\n",
    "        print(\"Validataion Accuracy:  {:.6f}\".format(validation_accuracy))\n",
    "    \n",
    "    saveCkpt(model_results_file, 1, netS, optimizerS, S_losses, iters)  \n",
    "    filename = model_ckpt_filename + \"_epochs_\" + str(start_epoch) + \"-\" + str(num_epochs) + \".pt\"\n",
    "    saveCkpt(filename, 1, netS, optimizerS, S_losses, iters)  \n",
    "    return S_losses, iters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a35e0-6db7-4654-a3a5-8ad656c44b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=1, start_epoch=1, iters=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76760e-6fb6-4fce-b30a-8381a9059621",
   "metadata": {},
   "source": [
    "## Training Round 2\n",
    "\n",
    "Next the model will be trained to match unenhanced good fingerprints to enhance fingerprint images. The hope is that this will help the network bridge the gap between matching enhanced fingerprint pairs to unenhanced fingerprint pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec1a27-de7f-458e-a776-c4cc59305e6c",
   "metadata": {},
   "source": [
    "### Set Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0676de-5c08-4308-9261-8d0911c045f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "torch.manual_seed(1)\n",
    "batch_size = 256\n",
    "\n",
    "kwargs = {}\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed(1)\n",
    "    kwargs = {'num_workers': ngpu, 'pin_memory': True}\n",
    "    \n",
    "target_dir =   \"/storage/Prepped_Fingerprints_206x300/Good/\"\n",
    "template_dir = \"/storage/Prepped_Fingerprints_206x300/Enhanced_Good/\"\n",
    "\n",
    "# Create the dataloader\n",
    "#num_train = 100000\n",
    "#num_valid = 4000\n",
    "num_train = 1000\n",
    "num_valid = 400\n",
    "data_loader = get_train_valid_test_loaders(target_dir, template_dir, batch_size, num_train, num_valid, shuffle, **kwargs)\n",
    "\n",
    "train_loader = data_loader[0]\n",
    "valid_loader = data_loader[1]\n",
    "test_loader = data_loader[2]\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "slr = 0.00002\n",
    "\n",
    "# Setup Adam optimizers for S\n",
    "optimizerS = optim.Adam(netS.parameters(), lr=slr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a5749-fa1d-4494-a43d-8557f8838e11",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "Below are some sample images that the Fingerprint Siamese Neural Network will be trained on. The top row consists of the unenhanced good quality fingerprints, which is a subset of the dataset consisting of around 100,000 fingerprint images with 10,000 unique fingerprints. The bottom row consists of the enhanaced fingerprint images, which is a different subset of the dataset that also consists of around 100,000 fingerprint images containing the same 10,000 unique fingerprints as the perviously described subset. Please note that the enhanced fingerprint subset was generated from the unenhanced good fingerprint subset using Gabor Filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f061ce-f8a8-45f7-b6d5-15020753020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "showSampleFingerprintPairs(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c376523-6077-41bf-a86f-504fc524248b",
   "metadata": {},
   "source": [
    "### Siamese Neural Network Training\n",
    "\n",
    "Finally, the model will be trained to match unenhanced fingerprint pairs of varying qualities (from really good to really bad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb3dda-e741-446f-8cb8-64c9e1df7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=10, start_epoch=4, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c25f67-630e-4131-9d0b-9ca1423ba7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=20, start_epoch=11, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba827f-a6b0-4f75-856a-abf36d89127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=30, start_epoch=21, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58ef39-27d3-4903-9ea3-ed98848d08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=40, start_epoch=31, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2b9f1-2e50-4b39-a541-067a89fb6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=50, start_epoch=41, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a62f7b-3007-4de0-ba62-8e6c1bba8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=60, start_epoch=51, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81334876-99f5-4045-9d7e-b6e630f20f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=70, start_epoch=61, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648d5b5-8dee-4430-bc3d-75bd566083a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=80, start_epoch=71, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f57ef-31da-4c86-85a3-e27b1a9d2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=90, start_epoch=81, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe984f3b-167f-46a0-bd2a-6506d125f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=100, start_epoch=91, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3bee0-d44d-4622-a821-daa846f9fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=110, start_epoch=101, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900bca5-b4d7-4bfc-9713-522f01419f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=120, start_epoch=111, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7deeb-e7ae-49f7-9dd2-7aa1ec34d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=130, start_epoch=121, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afdd97-7255-4996-9590-d892c8c28754",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=140, start_epoch=131, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68c305-1504-41e3-a22f-ee3e53bfb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=150, start_epoch=141, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbc980-dc24-4446-b3ee-e71feefc306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the Learning Rate\n",
    "slr = 0.0000002\n",
    "\n",
    "# Setup Adam optimizers for S\n",
    "optimizerS = optim.Adam(netS.parameters(), lr=slr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941f2dc-4143-433d-87ef-a1600dc04a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=160, start_epoch=151, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5687bc-7e5c-46b4-b366-5aac276dd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=170, start_epoch=161, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffe437-3061-4d3f-839a-66d1d1e51ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=180, start_epoch=171, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bd611-477c-40b1-a702-9fc22d0ed7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=190, start_epoch=181, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d549a5-6c68-486d-9dec-f1ad39f35f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=200, start_epoch=191, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d0880a-2c55-4869-b2e3-408f3da7e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=210, start_epoch=201, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f31e0-1595-4422-a25c-394f2f0a5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=220, start_epoch=211, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b378f2-a4fd-4f90-aefb-fc4fc62a8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=230, start_epoch=221, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381acc9-990b-433f-8727-5223370e208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=240, start_epoch=231, iters=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2356e8-5b43-4fc8-8213-8a8c4221b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_losses, iters = train(netS, num_train, num_valid, train_loader, valid_loader, device, S_losses=S_losses, num_epochs=250, start_epoch=241, iters=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb74f9-a75d-413a-800d-2b983bb62bad",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f01b08-2ee1-40c1-8c2f-a02207bbf750",
   "metadata": {},
   "source": [
    "### Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbd665-da9f-4bed-96e6-354f7aeb1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingLoss(S_losses):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Siamese Neural Network Training Loss\")\n",
    "    plt.plot(S_losses,label=\"Siamese NN Loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plotTrainingLoss(S_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c46e1-8874-4827-9b8b-4bd8bf8e7a20",
   "metadata": {},
   "source": [
    "## Sample Performance\n",
    "\n",
    "Below is plotted 8 pairs of fingerprints. Below each pair of fingerprints, the model will gives its prediction of whether each pair are of the same fingerprint or not. Below that is listed the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc7679-d598-4617-9e84-c0311c211a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLabels(labels):\n",
    "    c = 0\n",
    "    for l in labels:\n",
    "        if l == 1:\n",
    "            print(\"      same    \", end=\"\")\n",
    "        else:\n",
    "            print(\"      diff    \", end=\"\")\n",
    "        if c % 4 == 0:\n",
    "            print(\" \", end=\"\")\n",
    "        c += 1\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "def test(netS, loader, device):\n",
    "    # Validate\n",
    "    netS.eval()\n",
    "    validation_accuracy = 0.0\n",
    "    num_valid_correct = 0\n",
    "    total_valid = 0\n",
    "    for i, (x1, x2, y) in enumerate(loader): \n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        output = netS(x1, x2).view(-1)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        for i in range(len(output)):\n",
    "            label = 0.0\n",
    "            if output[i] > 0.5:\n",
    "                label = 1.0\n",
    "            if label == y[i]:\n",
    "                num_valid_correct += 1\n",
    "            total_valid += 1\n",
    "\n",
    "    validation_accuracy = num_valid_correct / total_valid * 100\n",
    "    print(\"Matching Accuracy over Test Dataset: {:.2f}%\".format(validation_accuracy))\n",
    "    \n",
    "\n",
    "def showTestPerformance(netS, test_loader, device):\n",
    "    batch = next(iter(test_loader))\n",
    "    labels = batch[2][:8]\n",
    "\n",
    "    # Let model make predictions\n",
    "    netS.eval()\n",
    "    output = netS(batch[0].to(device)[:8], batch[1].to(device)[:8]).view(-1)\n",
    "\n",
    "    # Display the Sample Images\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch[0].to(device)[:8], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch[1].to(device)[:8], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Display Model Performance\n",
    "    preds = [0 if x < 0.5 else 1 for x in output]\n",
    "\n",
    "    print(\"Pred: \")\n",
    "    printLabels(preds)\n",
    "\n",
    "    print(\"Truth:\")\n",
    "    printLabels(labels)  \n",
    "    \n",
    "    test(netS, test_loader, device)\n",
    "    \n",
    "showTestPerformance(netS, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb38b6-e7ca-40ad-9286-18e9a6c5b5c0",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614eaa8-2bb7-4f08-b76b-62c767311778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4906b4-25bb-4f16-ac37-56ff203c6788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
