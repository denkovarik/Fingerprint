from python import Python, PythonObject
from tensor import Tensor, TensorSpec, TensorShape, InputTensor, ManagedTensorSlice, OutputTensor
from utils.index import Index, IndexList
from memory.memory import memcpy
from structs.Utils import to_tensor


alias type = DType.float64


@value
struct MNIST_Data_Loader_Pytorch:
    var batchSize: Int
    var transform: PythonObject
    var dataset: PythonObject
    var dataloader: PythonObject
    var device: PythonObject
    var batchImages: List[PythonObject]
    var batchLabels: List[PythonObject]
    var train: Bool
    var shuffle: Bool
    var dataLoaderLength: Int
    
    fn __init__(mut self, batchSize: Int, device: PythonObject, train: Bool, shuffle: Bool) raises:
        var nn = Python.import_module("torch.nn")
        var optim = Python.import_module("torch.optim")
        var torch = Python.import_module("torch")
        var torchvision = Python.import_module("torchvision")
        var transforms = Python.import_module("torchvision.transforms")
        
        self.batchSize = batchSize
        self.device = device
        self.batchImages = List[PythonObject]()
        self.batchLabels = List[PythonObject]()
        self.train = train
        self.shuffle = shuffle
    
        # Define transformations
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        # Load or download the dataset
        self.dataset = torchvision.datasets.MNIST(root='data',train=train, download=True, transform=self.transform)
                
        self.dataloader = torch.utils.data.DataLoader(self.dataset, batch_size=self.batchSize, shuffle=shuffle)
        self.dataLoaderLength = len(self.dataloader)
     
        # Precompile all of the batches to avoid doing this in training loop
        for batch in self.dataloader:
            var images: PythonObject = batch[0]
            var labels: PythonObject = batch[1]            
            images = images.pin_memory()
            labels = labels.pin_memory()
            self.batchImages.append(images)
            self.batchLabels.append(labels)
            
    fn __len__(mut self) -> Int:
        return self.dataLoaderLength
        
        
@value
struct MNIST_Data_Loader_Mojo:
    var batchSize: Int
    var transform: PythonObject
    var dataset: PythonObject
    var dataloader: PythonObject
    var device: PythonObject
    var batchImages: List[Tensor[type]]
    var batchLabels: List[Tensor[DType.int64]]
    var train: Bool
    var shuffle: Bool
    var dataLoaderLength: Int
    
    fn __init__(mut self, batchSize: Int, device: PythonObject, train: Bool, shuffle: Bool) raises:
        var nn = Python.import_module("torch.nn")
        var optim = Python.import_module("torch.optim")
        var torch = Python.import_module("torch")
        var torchvision = Python.import_module("torchvision")
        var transforms = Python.import_module("torchvision.transforms")
        
        self.batchSize = batchSize
        self.device = device
        self.batchImages = List[Tensor[type]]()
        self.batchLabels = List[Tensor[DType.int64]]()
        self.train = train
        self.shuffle = shuffle
    
        # Define transformations
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        # Load or download the dataset
        self.dataset = torchvision.datasets.MNIST(root='data',train=train, download=True, transform=self.transform)
                
        self.dataloader = torch.utils.data.DataLoader(self.dataset, batch_size=self.batchSize, shuffle=shuffle)
        self.dataLoaderLength = len(self.dataloader)
        
        batchNum = 1
     
        # Precompile all of the batches to avoid doing this in training loop
        print("Loading dataset into Mojo Tensor")
        for batch in self.dataloader:
            batchNum = batchNum + 1
            var images: PythonObject = batch[0]
            
            var images_mojo: Tensor[type] = Tensor[type](TensorShape(self.batchSize, 1, 28, 28))                
            images_mojo = to_tensor(images.numpy())  
            
            var labels: PythonObject = batch[1]   
            var tensor_shape_list = List[Int]()
            tensor_shape_list.append(labels.shape[0])
            var labels_mojo = Tensor[DType.int64](TensorShape(tensor_shape_list))
            for i in range(labels.shape[0]):
                labels_mojo[i] = Int(labels[i])

            self.batchImages.append(images_mojo)
            self.batchLabels.append(labels_mojo)
            
        print("done")
            
    fn __len__(mut self) -> Int:
        return self.dataLoaderLength
        
        
def main():
    var torch = Python.import_module("torch")
    var batchSize: Int = 8
    var device: PythonObject = torch.device("cpu")

    # Load cifar10 dataset
    var trainloader = MNIST_Data_Loader_Mojo(batchSize=batchSize, device=device, train=True, shuffle=True)
    #var testloader = MNIST_Data_Loader_Mojo(batchSize=batchSize, device=device, train=False, shuffle=True)